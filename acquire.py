# This will be my Data Acquisition Module for my Social Vulnerability Project

# general imports
import pandas as pd


############ voter registration ###############################################

def get_voter_registration():
    '''
    This function will pull in a locally saved csv file that holds the 2018
    Voter Registration by Texas County
    '''
    df = pd.read_csv('voter_registration_2018.csv')
    return df

def initial_vr_clean(df):
    '''
    This function will take in the newly acquired 2018 Voter Registration by
    Texas County and eliminate superfluous columns and return only the info
    I want/need for my first iteration.
    '''
    # let's rename 'County Name' and 'Voter Registration'
    df = df.rename(columns=({'County Name': 'county', 'Voter Registration': 'registered'}))
    
    # Now let's drop columns we do not need for first iteration
    df = df[['county', 'registered']]
    
    # Convert 'registered' column to int
    df['registered'] = df['registered'].str.replace(',', '')
    df['registered'] = df['registered'].astype(int)
    
    # Let's write this to a csv so we have the clean table saved locally
    df.to_csv('vr_1.csv')
    
    return df


################### Voter Turnout #########################################

def get_voter_turnout():
    '''
    This function will pull in a locally saved csv file that holds the 2018
    Voter Turnout by Texas County
    '''
    df = pd.read_csv('voter_turnout_2018.csv')
    return df

def initial_vt_clean(df):
    '''
    This function will take in the newly acquired 2018 Voter Turnout by
    Texas County, reset the index, eliminate superfluous columns and return only the info
    I want/need for my first iteration.
    '''  
    # reset the index
    df = df.reset_index()
    
    # rename the old 'index' columns
    df = df.rename(columns=({'index': 'county', 'VOTER COUNT': 'turnout'}))
    
    # aggregate the turnout by county
    df = pd.DataFrame(df.groupby('county')['turnout'].sum()).reset_index()
    
    # Let's write this to a csv so we have the clean table saved locally
    df.to_csv('vt_1.csv')
    
    return df

############### CDC Social Vulnerability Index ##############################

def get_vulnerable():
    '''    
    This function will pull in a locally saved csv file that holds the 2018
    CDC Social Vulnerability Index dataset, classified by county.
    '''
    df = pd.read_csv('texas_COUNTY.csv')
    
    return df

def initial_svi_clean(df):
    '''
    This function will take in the newly acquired 2018 CDC Social Vulnerability Index, 
    reset the index, eliminate superfluous columns and return only the info
    I want/need for my first iteration.
    '''
    
    # reorder by county, and reset the index
    df = df.sort_values(by='COUNTY').reset_index()
    
    # Let's rename our columns
    df = df.rename(columns=({'COUNTY': 'county', 
                             'E_TOTPOP': 'population',
                             'M_TOTPOP': 'pop_error',
                             'RPL_THEME1': 'socioeconomic', 
                             'RPL_THEME2': 'composition', 
                             'RPL_THEME3': 'minority', 
                             'RPL_THEME4': 'housing', 
                             'RPL_THEMES': 'svi_ranking'}))
    
    # capitalize county names
    df['county'] = df['county'].str.upper()
    
    # now let's drop everything we don't need
    df = df[['county', 'population', 'pop_error', 'socioeconomic', 'composition', 'minority', 'housing', 'svi_ranking']]
    
    # Let's write this to a csv so we have the clean table saved locally
    df.to_csv('svi_1.csv')
    
    return df

################### Joining Tables ########################################

def county_data():
    '''
    This function will take in my locally stored csv files for each of the three tables I need, 
    perform intial cleaning functions on them, and merge them into 1 final pandas DataFrame.
    '''
    
    # first let's read in the csv files
    svi_df = pd.read_csv('svi_1.csv')
    vt_df = pd.read_csv('vt_1.csv')
    vr_df = pd.read_csv('vr_1.csv')
    
    # now let's merge them
    svi_vt_df = pd.merge(svi_df, vt_df, left_on='county', right_on='county', how='left')
    df = pd.merge(svi_vt_df, vr_df, left_on='county', right_on='county', how='left')
    
    # drop unnamed columns
    df = df.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y', 'Unnamed: 0'])
    
    # Drop null values
    df = df.dropna()
    
    # write the joined data to csv
    df.to_csv('county_first_iteration.csv')
    
    return df

################################ CDC SVI at Census Track Level ###################

def get_svi_ct():
    '''
    This function will pull in a locally saved csv file that holds the 2018
    CDC Social Vulnerability Index dataset, classified by census track.
    '''
    
    df = pd.read_csv('Texas.csv')
    
    return df

def initial_svi_ct_clean(df):
    '''
    This function will take in the newly acquired 2018 CDC Social Vulnerability Index
    by census track, resets the index, eliminate superfluous columns and return only the info
    I want/need for my first iteration.
    '''
    
    # reorder by county, and reset the index
    df = df.sort_values(by='COUNTY').reset_index()
    
    # Let's rename our columns
    df = df.rename(columns=({'COUNTY': 'county', 
                             'FIPS': 'fips',
                             'E_TOTPOP': 'population',
                             'M_TOTPOP': 'pop_error',
                             'RPL_THEME1': 'socioeconomic', 
                             'RPL_THEME2': 'composition', 
                             'RPL_THEME3': 'minority', 
                             'RPL_THEME4': 'housing', 
                             'RPL_THEMES': 'svi_ranking'}))
    
    # capitalize county names
    df['county'] = df['county'].str.upper()
    
    # now let's drop everything we don't need
    df = df[['county', 'fips', 'population', 'pop_error', 'socioeconomic', 'composition', 'minority', 'housing', 'svi_ranking']]
    
    # Let's write this to a csv so we have the clean table saved locally
    df.to_csv('svi_ct_1.csv')
    
    return df  

def census_data():
    '''
    This function will take in my locally stored csv files for each of the three tables I need, 
    perform intial cleaning functions on them, and merge them into 1 final pandas DataFrame.
    '''
    
    # first let's read in the csv files
    svi_ct_df = pd.read_csv('svi_ct_1.csv')
    vt_df = pd.read_csv('vt_1.csv')
    vr_df = pd.read_csv('vr_1.csv')
    
    # now let's merge them
    svi_vt_df = pd.merge(svi_ct_df, vt_df, left_on='county', right_on='county', how='left')
    df = pd.merge(svi_vt_df, vr_df, left_on='county', right_on='county', how='left')
    
    # drop unnamed columns
    df = df.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y', 'Unnamed: 0'])
    
    # Drop null values
    df = df.dropna()
    
    # write the joined data to csv
    df.to_csv('census_first_iteration.csv')
    
    return df

    
    
    
    